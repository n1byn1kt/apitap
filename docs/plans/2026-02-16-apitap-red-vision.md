# ApiTap Red â€” Vision Document
*2026-02-16 | Exploration & co-design with Dan*

---

## The Question

Should ApiTap Red be a separate product/repo, or a layer on top of ApiTap core?
How does pentesting recon actually work, and where does ApiTap slot in?

---

## How Pentesting Recon Actually Works

Professional penetration testing follows structured methodologies (PTES, NIST SP 800-115, OWASP WSTG). The standard phases:

### Phase 1: Pre-Engagement
- Scope definition, rules of engagement (RoE), written authorization
- What's in bounds, what's off-limits, communication protocols
- **ApiTap relevance:** None (this is contracts & planning)

### Phase 2: Reconnaissance (RECON)
This is where ApiTap shines. Two sub-phases:

**Passive Recon (OSINT) â€” Don't touch the target:**
- DNS enumeration (subdomains, MX records, TXT records)
- WHOIS, reverse DNS, certificate transparency logs
- Google dorks, Shodan, Censys
- Tech stack fingerprinting (Wappalyzer, BuiltWith)
- Employee OSINT (LinkedIn, GitHub, leaked creds via HIBP)
- JavaScript file analysis (API keys, endpoints, internal paths)
- Tools: subfinder, theHarvester, amass, Shodan CLI

**Active Recon â€” Touch the target:**
- Port scanning (nmap)
- Service/version detection
- Web crawling / spidering
- **API endpoint discovery â† THIS IS APITAP'S SWEET SPOT**
- Directory/file brute-forcing (ffuf, dirsearch, feroxbuster)
- Parameter discovery
- WAF detection
- Tools: nmap, ffuf, Burp Suite, nikto

### Phase 3: Vulnerability Analysis
- Automated scanning (Nessus, Nuclei, Burp Scanner)
- Manual validation (eliminate false positives)
- Custom checks against OWASP API Top 10
- **ApiTap opportunity:** Pattern detection in captured traffic

### Phase 4: Exploitation
- Prove the vuln is real â€” get a shell, extract data, bypass auth
- Tools: Metasploit, custom scripts, Burp Repeater/Intruder
- **ApiTap opportunity:** Replay endpoints with modified params/tokens

### Phase 5: Post-Exploitation
- Privilege escalation, lateral movement, data exfiltration
- **ApiTap relevance:** Limited (this is network/OS level)

### Phase 6: Reporting
- Executive summary + technical details + reproduction steps
- OWASP/MITRE ATT&CK mapping
- **ApiTap opportunity:** Skill files = machine-readable proof of exploit

---

## Where ApiTap Fits in the Kill Chain

```
                    WHAT EXISTS TODAY              WHAT WE'D BUILD
                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Phase 2 (Recon)     âœ… apitap_capture             ğŸ”´ Endpoint scoring
                    âœ… apitap_browse              ğŸ”´ Auth detection report
                    âœ… apitap_discover            ğŸ”´ Tech stack fingerprint
                    âœ… apitap_peek                ğŸ”´ Hidden endpoint fuzzing
                    âœ… apitap_search              ğŸ”´ GraphQL introspection detect

Phase 3 (Vuln)      âœ… Skill files capture         ğŸ”´ IDOR pattern detection
                       response structure          ğŸ”´ Auth bypass testing
                    âœ… apitap_replay              ğŸ”´ Mass assignment detect
                                                  ğŸ”´ Rate limit testing
                                                  ğŸ”´ OWASP API Top 10 checks

Phase 4 (Exploit)   âœ… apitap_replay              ğŸ”´ Parameter fuzzing
                    âœ… apitap_replay_batch        ğŸ”´ Auth boundary testing
                    âœ… Auth storage (AES-256)     ğŸ”´ Token manipulation
                                                  ğŸ”´ Privilege escalation diff

Phase 6 (Report)    âœ… Structured JSON output      ğŸ”´ OWASP mapping
                    âœ… Skill file = proof          ğŸ”´ Markdown/PDF report gen
                                                  ğŸ”´ Remediation suggestions
```

**Key insight:** ApiTap already owns Phase 2 (recon) better than any existing tool for API discovery. The gap is Phase 3-4 analysis â€” turning captured data into security findings.

---

## The Competitive Landscape (Feb 2026)

### What exists today:

| Tool | What it does | Gap |
|------|-------------|-----|
| **Burp Suite** ($449/yr) | Proxy + scanner + repeater | Manual, expensive, not MCP-native |
| **Caido** | Modern Burp alternative | Still manual, no AI/agent integration |
| **Nuclei** (free) | Template-based vuln scanning | No API discovery â€” needs known endpoints |
| **pentestMCP** | MCP bridge to CLI tools | Tool server only, no intelligence |
| **HexStrike-AI** | Large MCP bridge for offensive tools | Kitchen sink approach, high risk |
| **PentestGPT** | AI-assisted pentest pipeline | Docker-heavy, general purpose |
| **Strix** | Multi-agent pentest platform | Enterprise/CI focus, not API-first |

### ApiTap Red's unique angle:
1. **Discovery-first:** We find the APIs. Everyone else assumes you already know them.
2. **MCP-native:** Built for AI agents from day one, not bolted on.
3. **Skill files as artifacts:** Captured traffic = replayable proof = reporting evidence.
4. **Already hardened:** 9/10 security posture. We've done to ourselves what we'd help others do.
5. **Privacy-first:** Fully local. No cloud proxy. Your target data stays on your machine.

**Nobody does: discover API surface â†’ analyze for vulns â†’ test â†’ report in one tool.**
Pentesters currently chain 5-6 tools. ApiTap Red could collapse that.

---

## Product Architecture: Three Options

### Option A: Plugin Layer (Recommended to start)
```
@apitap/core          â† Existing. npm package. 12 tools.
@apitap/red           â† New package. Imports core. Adds security analysis.
                         Same repo, separate entry point.
```

**Pros:** Single repo, shared codebase, ships as `apitap red` CLI or `apitap mcp --red`
**Cons:** Couples release cycles

### Option B: Separate Repo
```
n1byn1kt/apitap       â† Core tool (BSL 1.1)
n1byn1kt/apitap-red   â† Security extension (different license?)
```

**Pros:** Independent release, could have different license (more restrictive?)
**Cons:** Dependency management, split community

### Option C: Skill File (Lightest)
```
~/.apitap/skills/     â† Existing skill directory
security-audit.skill  â† New: security analysis patterns
```

ApiTap Red = a collection of security-focused skill files + a few new MCP tools. No new package at all â€” just specialized usage of existing tools.

**Pros:** Zero new infrastructure, Dan could contribute skill files directly
**Cons:** Limited â€” can't do analysis that requires new code

### Decision: Option B â€” Separate Private Repo

**ApiTap Red will NOT be public.** Offensive security tools in the wrong hands = liability, especially with APT31 already weaponizing MCP tooling (GTIG Feb 2026).

```
n1byn1kt/apitap       â† Public (BSL 1.1). The Leatherman.
n1byn1kt/apitap-red   â† Private. Invite-only (Jaromir + Dan). The scalpel.
```

Red imports `@apitap/core` from npm as a dependency. No security analysis code touches the public repo. Ever.

---

## Phase 1: Start with RECON (Dan's suggestion)

**Why recon first:** It's the safest, most immediately useful, and doesn't require authorization beyond the tester's own scope. It's also where ApiTap already excels.

### What "ApiTap Recon" looks like:

```bash
# Step 1: Capture full API surface
apitap capture https://target.com --duration 120

# Step 2: Recon report (NEW)
apitap red recon target.com
```

**Recon report would output:**

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ApiTap Recon Report: target.com
  Captured: 47 endpoints | 12 unique paths
  Duration: 2m 3s | Traffic: 284 requests
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ENDPOINT CLASSIFICATION
â”œâ”€ Auth endpoints:     3  (login, register, token-refresh)
â”œâ”€ Data endpoints:    28  (CRUD operations)
â”œâ”€ Admin endpoints:    2  âš ï¸  (/admin/users, /admin/config)
â”œâ”€ Debug endpoints:    1  ğŸ”´ (/debug/healthcheck)
â”œâ”€ File upload:        1  âš ï¸  (/api/upload)
â”œâ”€ GraphQL:            0
â””â”€ WebSocket:          1

ğŸ”‘ AUTH ANALYSIS
â”œâ”€ Auth type: Bearer JWT
â”œâ”€ Token in: Authorization header
â”œâ”€ Refresh endpoint: POST /api/auth/refresh
â”œâ”€ Token expiry: 3600s
â”œâ”€ âš ï¸  2 endpoints respond 200 WITHOUT auth token
â”‚   â”œâ”€ GET /api/public/config
â”‚   â””â”€ GET /api/users/:id  â† POSSIBLE IDOR

ğŸ” PARAMETER PATTERNS
â”œâ”€ Sequential IDs: /api/users/:id, /api/orders/:id  âš ï¸ IDOR candidate
â”œâ”€ UUID patterns: /api/sessions/:uuid  âœ…
â”œâ”€ Sensitive params: ?email=, ?ssn=  ğŸ”´ PII in query string
â””â”€ Batch endpoints: /api/users?limit=&offset=  (enumeration risk)

ğŸ—ï¸ TECH STACK (inferred)
â”œâ”€ Server: nginx/1.24
â”œâ”€ Framework: Express (X-Powered-By header)
â”œâ”€ API style: REST (JSON)
â”œâ”€ CORS: *, allows credentials  ğŸ”´
â””â”€ Rate limiting: None detected  âš ï¸

ğŸ“‹ OWASP API TOP 10 SURFACE
â”œâ”€ API1 (BOLA/IDOR):       3 endpoints at risk  ğŸ”´
â”œâ”€ API2 (Broken Auth):     2 endpoints no auth   âš ï¸
â”œâ”€ API3 (Property Auth):   Unknown (need testing)
â”œâ”€ API4 (Resource Limit):  No rate limiting       âš ï¸
â”œâ”€ API5 (Function Auth):   Admin paths exposed    ğŸ”´
â”œâ”€ API9 (Inventory Mgmt):  Debug endpoint live    ğŸ”´
â””â”€ API10 (Unsafe Consume):  Unknown
```

### What this requires technically:

**New MCP tools (3-4):**
| Tool | What it does |
|------|-------------|
| `apitap_recon` | Generate recon report from skill files |
| `apitap_classify` | Classify endpoints (auth, admin, debug, CRUD) |
| `apitap_auth_probe` | Test which endpoints work without auth |
| `apitap_diff` | Compare responses across auth levels |

**Analysis logic (reads existing skill files):**
- Parse captured endpoints for ID patterns (sequential vs UUID)
- Detect auth headers/cookies in captured requests
- Flag endpoints that returned data without auth
- Identify sensitive parameter names
- Infer tech stack from headers
- Map to OWASP API Top 10 categories

**Key point:** All of this runs on *already captured data*. No new requests to the target needed for the basic recon report. The auth_probe and diff tools would make new requests (with permission).

---

## Dan's Role

### What Dan can do right now (with ApiTap core):

1. **Install:** `npm install -g @apitap/core`
2. **Capture a test target:** 
   - Use OWASP Juice Shop, DVWA, or any authorized target
   - `apitap capture https://juice-shop.example.com`
3. **Review skill files:** Look at what's captured, what's missing
4. **Try replay:** `apitap replay juice-shop.example.com <endpoint>`
5. **Break it:** Try to make ApiTap do things it shouldn't
6. **Feedback:** What would you need in a recon report?

### What Dan brings:
- Real pen test workflows â€” what actually matters vs what sounds cool
- Edge cases from real engagements
- Validation of whether our recon output is actionable
- "Would you actually use this?" filter

### Co-design sessions:
1. **Session 1:** Dan reviews core tool, reports what works/breaks
2. **Session 2:** Design recon report format together (what fields matter?)
3. **Session 3:** Prototype `apitap red recon` based on Dan's feedback
4. **Session 4:** Test on OWASP targets, iterate

---

## OWASP API Security Top 10 (2023) â€” What We Can Detect

| # | Risk | Can ApiTap Detect? | How |
|---|------|--------------------|-----|
| API1 | Broken Object Level Auth (BOLA) | ğŸŸ¡ Partial | Sequential ID patterns in paths |
| API2 | Broken Authentication | ğŸŸ¡ Partial | Endpoints responding without tokens |
| API3 | Broken Object Property Auth | ğŸ”´ Needs testing | Requires response diffing across users |
| API4 | Unrestricted Resource Consumption | ğŸŸ¢ Yes | Detect missing rate limit headers |
| API5 | Broken Function Level Auth | ğŸŸ¡ Partial | Admin/debug endpoints in captured traffic |
| API6 | Unrestricted Sensitive Business Flows | ğŸ”´ Needs context | Business logic specific |
| API7 | SSRF | ğŸŸ¢ Yes (ironic) | We literally hardened against this |
| API8 | Security Misconfiguration | ğŸŸ¢ Yes | CORS, headers, debug endpoints |
| API9 | Improper Inventory Management | ğŸŸ¢ Yes | Version headers, deprecated paths |
| API10 | Unsafe Consumption of APIs | ğŸ”´ Needs testing | Third-party API calls in traffic |

**5 of 10 detectable from captured traffic alone. 3 more with active testing. 2 need business context.**

---

## Nuclei Integration Angle

Nuclei (ProjectDiscovery) uses YAML templates for vuln detection. There's a natural bridge:

```
ApiTap captures endpoints â†’ generates Nuclei templates â†’ Nuclei runs the tests
```

This means we don't have to build our own scanner from scratch. ApiTap discovers the attack surface, Nuclei tests it. Best of both tools.

Example flow:
```bash
# 1. ApiTap captures API surface
apitap capture https://target.com

# 2. ApiTap generates Nuclei templates (NEW)
apitap red nuclei-gen target.com --output templates/

# 3. Nuclei runs the generated templates
nuclei -t templates/ -u https://target.com
```

---

## License Considerations

- **Core ApiTap:** BSL 1.1 (public)
- **ApiTap Red:** Private repo, no public license needed. Access = invite only.
- If it ever goes public (unlikely), consider AGPL or proprietary to prevent weaponization.

---

## Timeline (Rough)

| Week | Milestone |
|------|-----------|
| 1 | Dan reviews core tool, provides feedback |
| 2 | Design recon report format, prototype `apitap_recon` |
| 3 | Build endpoint classifier + auth prober |
| 4 | OWASP API Top 10 mapping, test on Juice Shop |
| 5-6 | Nuclei template generation |
| 7-8 | Reporting layer, polish |

**v0.1 = just recon.** Get that right, then layer on active testing.

---

## Open Questions for Dan

1. What does your current recon workflow look like? (Tools, order, time spent)
2. What format do you want recon output in? (Markdown, JSON, HTML?)
3. What test targets can we use? (Juice Shop, DVWA, HackTheBox, real authorized targets?)
4. How do you handle auth during pen tests? (Provided creds? Self-registered? Both?)
5. What's the most time-consuming manual step in API recon?
6. Would you want this integrated into your existing toolchain (Burp, Nuclei) or standalone?
7. What do clients actually care about in reports?

---

## Summary

**Start with recon. It's safe, useful, and plays to ApiTap's strengths.**

ApiTap already does the hardest part â€” discovering and parameterizing API surfaces automatically. The gap is turning that raw data into security intelligence. That's what ApiTap Red adds.

Private repo (`n1byn1kt/apitap-red`), imports `@apitap/core` as dependency. Dan tests core now, co-designs the analysis layer, we build it together. Never published publicly.

**The pitch in one line:** *"ApiTap finds the APIs. ApiTap Red finds the vulns."*
